{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "from txttk.retools import *\n",
    "from itertools import product\n",
    "from pptx import Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_bible_text():\n",
    "    with codecs.open('bibletk/hb5.txt', encoding='big5', errors='ignore') as f:\n",
    "        return f.read().strip()\n",
    "    \n",
    "def parse_bible(bible_text):\n",
    "    pharses = bible_text.split('\\n')[1:]\n",
    "    return pharses\n",
    "\n",
    "def build_repository(pharses):\n",
    "    repository = {}\n",
    "    for pharse in pharses:\n",
    "        book, _, other = pharse.partition(' ')\n",
    "        locator, _, context = other.partition(' ')\n",
    "        repository[' '.join([book, locator])] = context\n",
    "    return repository\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pharses = parse_bible(load_bible_text())\n",
    "repository = build_repository(pharses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book_map = {}\n",
    "bookid2chinese = {}\n",
    "with open('bibletk/book_names.txt') as f:\n",
    "    for row in filter(lambda x: len(x)>3 and x[:4]!='中文卷名', f):\n",
    "        chinese_long, chinese_short, engl_long, engl_short = row.strip().split('\\t')\n",
    "        the_map = {\n",
    "            chinese_long: engl_short,\n",
    "            chinese_short: engl_short,\n",
    "            #engl_long: engl_short,\n",
    "            #engl_short: engl_short\n",
    "        }\n",
    "        book_map.update(the_map)\n",
    "        bookid2chinese[engl_short] = chinese_long\n",
    "\n",
    "        \n",
    "book_names = book_map.keys()\n",
    "bookname_regex = condense(book_names).replace('\\\\', '')\n",
    "locator_pattern = r'(?P<locator>[一二三四五六七八九十廿卅百\\d:\\-\\,]+)'\n",
    "filter_pattern = concat(['(?P<book>{})'.format(bookname_regex), locator_pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def name_normalize(name):\n",
    "    return book_map[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def candidate_filter(context):\n",
    "    \"\"\"\n",
    "    Return the candidate from context\n",
    "    \"\"\"\n",
    "    pattern = '((?P<book>加(拉太書)?|士(師記)?|(耶利米哀|雅)?歌|約(翰福音|翰貳書|翰壹書|書亞記|翰參書|伯記|珥書|拿書|三|二|一)?|耶(利米書)?|啟(示錄)?|申(命記)?|(帖撒羅尼迦前|帖撒羅尼迦後|提摩太後|撒迦利亞|提摩太前|哥林多前|俄巴底亞|哥林多後|哈巴谷|彼得後|以西結|彼得前|西番雅|阿摩司|腓利門|腓利比|歌羅西|瑪拉基|以弗所|但以理|以賽亞|希伯來|何西阿|雅各|哈該|羅馬|那鴻|彌迦|猶大|提多|傳道)?書|路(加福音|得記)?|(使徒行)?傳|民(數記)?|利(未記)?|創(世記)?|尼(希米記)?|詩(篇)?|箴(言)?|出(埃及記)?|彌|得|伯|提前|來|撒母耳記下|以斯拉記|但|何|太|拉|腓|以斯帖記|歷代志上|歷代志下|王上|徒|賽|羅|彼前|代上|門|該|拿|林後|彼後|番|帖前|撒上|撒母耳記上|哈|亞|摩|斯|帖後|俄|鴻|代下|撒下|列王紀上|馬太福音|馬可福音|列王紀下|弗|猶|王下|瑪|多|提後|可|哀|雅|結|西|珥|林前))(?P<locator>[一二三四五六七八九十廿卅百章\\\\d:\\\\-]+)'\n",
    "    yield from re.finditer(pattern, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def candidate_tokenizer(context):\n",
    "    \"\"\"\n",
    "    Pick the candidate from context\n",
    "    \"\"\"\n",
    "    pattern = '((?P<out>.*?)(?P<book>加(拉太書)?|士(師記)?|(耶利米哀|雅)?歌|約(翰福音|翰貳書|翰壹書|書亞記|翰參書|伯記|珥書|拿書|三|二|一)?|耶(利米書)?|啟(示錄)?|申(命記)?|(帖撒羅尼迦前|帖撒羅尼迦後|提摩太後|撒迦利亞|提摩太前|哥林多前|俄巴底亞|哥林多後|哈巴谷|彼得後|以西結|彼得前|西番雅|阿摩司|腓利門|腓利比|歌羅西|瑪拉基|以弗所|但以理|以賽亞|希伯來|何西阿|雅各|哈該|羅馬|那鴻|彌迦|猶大|提多|傳道)?書|路(加福音|得記)?|(使徒行)?傳|民(數記)?|利(未記)?|創(世記)?|尼(希米記)?|詩(篇)?|箴(言)?|出(埃及記)?|彌|得|伯|提前|來|撒母耳記下|以斯拉記|但|何|太|拉|腓|以斯帖記|歷代志上|歷代志下|王上|徒|賽|羅|彼前|代上|門|該|拿|林後|彼後|番|帖前|撒上|撒母耳記上|哈|亞|摩|斯|帖後|俄|鴻|代下|撒下|列王紀上|馬太福音|馬可福音|列王紀下|弗|猶|王下|瑪|多|提後|可|哀|雅|結|西|珥|林前))(?P<locator>[一二三四五六七八九十廿卅百章\\\\d:\\\\-]+)'\n",
    "    yield from re.finditer(pattern, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_map = {'一':1, \n",
    "            '二':2, \n",
    "            '三':3, \n",
    "            '四':4, \n",
    "            '五':5, \n",
    "            '六':6, \n",
    "            '七':7, \n",
    "            '八':8, \n",
    "            '九':9, \n",
    "            '十':10, \n",
    "            '廿':20, \n",
    "            '卅':30, \n",
    "            '百':100, }\n",
    "\n",
    "def translate_number(chinese_number): \n",
    "    \"\"\"\n",
    "    Translate chinese number less than 999 into int\n",
    "    \n",
    "    >>> translate_number('一百八十二')\n",
    "    182\n",
    "    >>> translate_number('廿三')\n",
    "    23\n",
    "    \"\"\"\n",
    "    pattern = r'((?P<hundred>.百)?)(?P<lesser_than_100>{})'.format('[一二三四五六七八九十廿卅]*')\n",
    "    number = 0\n",
    "    m = re.match(pattern, chinese_number)\n",
    "\n",
    "\n",
    "    if m.group('hundred'):\n",
    "        number += number_map[m.group('hundred')[0]] * 100\n",
    "    lesser_than_100 = m.group('lesser_than_100')\n",
    "    pattern = r'(?P<ten>.十)?(?P<one>.+)'\n",
    "    m = re.match(pattern, lesser_than_100)\n",
    "    if m.group('ten'):\n",
    "        number += number_map[m.group('ten')[0]] * 10\n",
    "    if m.group('one'):\n",
    "        number += sum([number_map[char] for char in m.group('one')])\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spliter(re_match_from_filter):\n",
    "    \"\"\"\n",
    "    Split given re.match object from candidate filter into (book, locator) tuple \n",
    "    \"\"\"\n",
    "    book = re_match_from_filter.group('book')\n",
    "    locator = re_match_from_filter.group('locator')\n",
    "    return (book, locator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_range(range_text):\n",
    "    \"\"\"\n",
    "    Split a range text such as '3-5' into [3, 4, 5]\n",
    "    \"\"\"\n",
    "    \n",
    "    sep = '-'\n",
    "    if sep in range_text:\n",
    "        start, end = (int(n) for n in range_text.split(sep))\n",
    "        return list(range(start, end + 1))\n",
    "    else:\n",
    "        return [int(range_text)]\n",
    "    \n",
    "def parse_locator(locator):\n",
    "    \"\"\"\n",
    "    Parse given locator such as '一5', '5章2-3'\n",
    "    \"\"\"\n",
    "    pattern = r'(?:(?P<number>\\d+)|(?P<chinese>[一二三四五六七八九十廿卅百]+))[章:]?(?P<pharse_range>[\\d,\\-]+)'\n",
    "    m = re.match(pattern, locator)\n",
    "    if m.group('number'):\n",
    "        chapter = int(m.group('number'))\n",
    "    else:\n",
    "        chapter = translate_number(m.group('chinese'))\n",
    "    range_text = m.group('pharse_range')\n",
    "    pharse_list = parse_range(range_text)\n",
    "    return chapter, pharse_list\n",
    "\n",
    "def get_bucket(re_match_from_filter):\n",
    "    \"\"\"\n",
    "    From given re.match object from candidate_filter, \n",
    "    return a bucket (a list) of bible identifiers (bookid, chapter, pharse)\n",
    "    \"\"\"\n",
    "    book, locator = spliter(re_match_from_filter)\n",
    "    chapter, pharse_list = parse_locator(locator)\n",
    "    bucket = [(name_normalize(book), chapter, pharse) for pharse in pharse_list]\n",
    "    return bucket\n",
    "\n",
    "def get_context(book, chapter, pharse):\n",
    "    \"\"\"\n",
    "    Given book, chapter, and pharse number, return the bible context.\n",
    "    \"\"\"\n",
    "    context = repository['{} {}:{}'.format(book, chapter, pharse)]\n",
    "    return context\n",
    "\n",
    "def format_bucket(bucket):\n",
    "    bookids = [pharse[0] for pharse in bucket]\n",
    "    assert len(set(bookids)) == 1\n",
    "    bookid = bookids[0]\n",
    "    bookname = bookid2chinese[bookid]\n",
    "    chapters = [pharse[1] for pharse in bucket]\n",
    "    assert len(set(chapters)) == 1\n",
    "    chapter = chapters[0]\n",
    "    header = '{}{}章'.format(bookname, chapter)\n",
    "    body = ''.join(['{}{}'.format(p[2], get_context(*p)) for p in bucket])\n",
    "    return header, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "先《創世記1章：1起初　神創造天地。2地是空虛混沌．淵面黑暗．　神的靈運行在水面上。》，然後《創世記3章：1耶和華　神所造的、惟有蛇比田野一切的活物更狡猾。蛇對女人說、　神豈是真說、不許你們喫園中所有樹上的果子麼。2女人對蛇說、園中樹上的果子我們可以喫．》,結束\n"
     ]
    }
   ],
   "source": [
    "context = '先創一1-2，然後創三1-2,結束'\n",
    "def text_expand(context):\n",
    "    output = []\n",
    "    end = 0\n",
    "    for m in candidate_tokenizer(context):\n",
    "        output.append(m.group('out'))\n",
    "        try:\n",
    "            bucket = get_bucket(m)\n",
    "            formated = format_bucket(bucket)\n",
    "            output.extend(['《','：'.join(list(formated)), '》'])\n",
    "        except KeyError:\n",
    "            output.append(m.group(0))\n",
    "        end = m.end()\n",
    "    output.append(context[end:])\n",
    "    return ''.join(output)\n",
    "    \n",
    "print(text_expand(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = re.search('a', '0001a002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert '_sre.SRE_Match' object to str implicitly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a2fafb6b0d1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_picker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_start\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeroyang/.pyenv/versions/bibletk/lib/python3.5/site-packages/txttk/nlptools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(context, base)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert '_sre.SRE_Match' object to str implicitly"
     ]
    }
   ],
   "source": [
    "from txttk.nlptools import count_start\n",
    "new_picker = count_start(candidate_picker)\n",
    "context = '我就在創二32發現'\n",
    "output = []\n",
    "start = 0\n",
    "for candidate, new_start in new_picker(context, 0):\n",
    "    output.append(context[start, new_start])\n",
    "    output.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 7), match='創世記2:32'>\n",
      "[('Gen', 2, 32)]\n"
     ]
    }
   ],
   "source": [
    "for can in candidate_filter('創世記2:32'):\n",
    "    print(can)\n",
    "    print(get_bucket(can))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bibletk import bibletk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 7), match='創世記2:32'>\n",
      "[('Gen', 2, 32)]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for can in bibletk.candidate_filter('創世記2:32'):\n",
    "    print(can)\n",
    "    bucket = bibletk.get_bucket(can)\n",
    "    print(bucket)\n",
    "    print(bibletk.get_context(*bucket[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "先《創世記1章：1起初　神創造天地。2地是空虛混沌．淵面黑暗．　神的靈運行在水面上。》，然後《創世記3章：1耶和華　神所造的、惟有蛇比田野一切的活物更狡猾。蛇對女人說、　神豈是真說、不許你們喫園中所有樹上的果子麼。2女人對蛇說、園中樹上的果子我們可以喫．》,結束"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
