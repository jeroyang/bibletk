{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "from txttk.retools import *\n",
    "from itertools import product\n",
    "from pptx import Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_bible_text():\n",
    "    with codecs.open('data/hb5.txt', encoding='big5', errors='ignore') as f:\n",
    "        return f.read().strip()\n",
    "    \n",
    "def parse_bible(bible_text):\n",
    "    pharses = bible_text.split('\\n')[1:]\n",
    "    return pharses\n",
    "\n",
    "def build_repository(pharses):\n",
    "    repository = {}\n",
    "    for pharse in pharses:\n",
    "        book, _, other = pharse.partition(' ')\n",
    "        locator, _, context = other.partition(' ')\n",
    "        repository[' '.join([book, locator])] = context\n",
    "    return repository\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pharses = parse_bible(load_bible_text())\n",
    "repository = build_repository(pharses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book_map = {}\n",
    "bookid2chinese = {}\n",
    "with open('data/book_names.txt') as f:\n",
    "    for row in filter(lambda x: len(x)>3 and x[:4]!='中文卷名', f):\n",
    "        chinese_long, chinese_short, engl_long, engl_short = row.strip().split('\\t')\n",
    "        the_map = {\n",
    "            chinese_long: engl_short,\n",
    "            chinese_short: engl_short,\n",
    "            #engl_long: engl_short,\n",
    "            #engl_short: engl_short\n",
    "        }\n",
    "        book_map.update(the_map)\n",
    "        bookid2chinese[engl_short] = chinese_long\n",
    "\n",
    "        \n",
    "book_names = book_map.keys()\n",
    "bookname_regex = condense(book_names).replace('\\\\', '')\n",
    "locator_pattern = r'(?P<locator>[一二三四五六七八九十廿卅百\\d:\\-\\,]+)'\n",
    "filter_pattern = concat(['(?P<book>{})'.format(bookname_regex), locator_pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def name_normalize(name):\n",
    "    return book_map[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def candidate_filter(context):\n",
    "    \"\"\"\n",
    "    Return the candidate from context\n",
    "    \"\"\"\n",
    "    pattern = '((?P<book>加(拉太書)?|士(師記)?|(耶利米哀|雅)?歌|約(翰福音|翰貳書|翰壹書|書亞記|翰參書|伯記|珥書|拿書|三|二|一)?|耶(利米書)?|啟(示錄)?|申(命記)?|(帖撒羅尼迦前|帖撒羅尼迦後|提摩太後|撒迦利亞|提摩太前|哥林多前|俄巴底亞|哥林多後|哈巴谷|彼得後|以西結|彼得前|西番雅|阿摩司|腓利門|腓利比|歌羅西|瑪拉基|以弗所|但以理|以賽亞|希伯來|何西阿|雅各|哈該|羅馬|那鴻|彌迦|猶大|提多|傳道)?書|路(加福音|得記)?|(使徒行)?傳|民(數記)?|利(未記)?|創(世記)?|尼(希米記)?|詩(篇)?|箴(言)?|出(埃及記)?|彌|得|伯|提前|來|撒母耳記下|以斯拉記|但|何|太|拉|腓|以斯帖記|歷代志上|歷代志下|王上|徒|賽|羅|彼前|代上|門|該|拿|林後|彼後|番|帖前|撒上|撒母耳記上|哈|亞|摩|斯|帖後|俄|鴻|代下|撒下|列王紀上|馬太福音|馬可福音|列王紀下|弗|猶|王下|瑪|多|提後|可|哀|雅|結|西|珥|林前))(?P<locator>[一二三四五六七八九十廿卅百章\\\\d:\\\\-\\\\,]+)'\n",
    "    yield from re.finditer(pattern, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_map = {'一':1, \n",
    "            '二':2, \n",
    "            '三':3, \n",
    "            '四':4, \n",
    "            '五':5, \n",
    "            '六':6, \n",
    "            '七':7, \n",
    "            '八':8, \n",
    "            '九':9, \n",
    "            '十':10, \n",
    "            '廿':20, \n",
    "            '卅':30, \n",
    "            '百':100, }\n",
    "\n",
    "def translate_number(chinese_number): \n",
    "    \"\"\"\n",
    "    Translate chinese number less than 999 into int\n",
    "    \n",
    "    >>> translate_number('一百八十二')\n",
    "    182\n",
    "    >>> translate_number(')\n",
    "    \"\"\"\n",
    "    pattern = r'((?P<hundred>.百)?)(?P<lesser_than_100>{})'.format('[一二三四五六七八九十廿卅]*')\n",
    "    number = 0\n",
    "    m = re.match(pattern, chinese_number)\n",
    "\n",
    "\n",
    "    if m.group('hundred'):\n",
    "        number += number_map[m.group('hundred')[0]] * 100\n",
    "    lesser_than_100 = m.group('lesser_than_100')\n",
    "    pattern = r'(?P<ten>.十)?(?P<one>.+)'\n",
    "    m = re.match(pattern, lesser_than_100)\n",
    "    if m.group('ten'):\n",
    "        number += number_map[m.group('ten')[0]] * 10\n",
    "    if m.group('one'):\n",
    "        number += sum([number_map[char] for char in m.group('one')])\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spliter(re_match_from_filter):\n",
    "    \"\"\"\n",
    "    Split given re.match object from candidate filter into (book, locator) tuple \n",
    "    \"\"\"\n",
    "    book = re_match_from_filter.group('book')\n",
    "    locator = re_match_from_filter.group('locator')\n",
    "    return (book, locator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_range(range_text):\n",
    "    \"\"\"\n",
    "    Split a range text such as '3-5' into [3, 4, 5]\n",
    "    \"\"\"\n",
    "    \n",
    "    sep = '-'\n",
    "    if sep in range_text:\n",
    "        start, end = (int(n) for n in range_text.split(sep))\n",
    "        return list(range(start, end + 1))\n",
    "    else:\n",
    "        return [int(range_text)]\n",
    "    \n",
    "def parse_locator(locator):\n",
    "    \"\"\"\n",
    "    Parse given locator such as '一5', '5章2-3'\n",
    "    \"\"\"\n",
    "    pattern = r'(?:(?P<number>\\d+)|(?P<chinese>[一二三四五六七八九十廿卅百]+))[章:]?(?P<pharse_range>[\\d,\\-]+)'\n",
    "    m = re.match(pattern, locator)\n",
    "    if m.group('number'):\n",
    "        chapter = int(m.group('number'))\n",
    "    else:\n",
    "        chapter = translate_number(m.group('chinese'))\n",
    "    range_text = m.group('pharse_range')\n",
    "    pharse_list = parse_range(range_text)\n",
    "    return chapter, pharse_list\n",
    "\n",
    "def get_bucket(re_match_from_filter):\n",
    "    \"\"\"\n",
    "    From given re.match object from candidate_filter, \n",
    "    return a bucket (a list) of bible identifiers (bookid, chapter, pharse)\n",
    "    \"\"\"\n",
    "    book, locator = spliter(re_match_from_filter)\n",
    "    chapter, pharse_list = parse_locator(locator)\n",
    "    bucket = [(name_normalize(book), chapter, pharse) for pharse in pharse_list]\n",
    "    return bucket\n",
    "\n",
    "def get_context(book, chapter, pharse):\n",
    "    \"\"\"\n",
    "    Given book, chapter, and pharse number, return the bible context.\n",
    "    \"\"\"\n",
    "    context = repository['{} {}:{}'.format(book, chapter, pharse)]\n",
    "    return context\n",
    "\n",
    "def format_bucket(bucket):\n",
    "    bookids = [pharse[0] for pharse in bucket]\n",
    "    assert len(set(bookids)) == 1\n",
    "    bookid = bookids[0]\n",
    "    bookname = bookid2chinese[bookid]\n",
    "    chapters = [pharse[1] for pharse in bucket]\n",
    "    assert len(set(chapters)) == 1\n",
    "    chapter = chapters[0]\n",
    "    header = '{}{}章'.format(bookname, chapter)\n",
    "    body = ''.join(['{}{}'.format(p[2], get_context(*p)) for p in bucket])\n",
    "    return header, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_pptx(filename, pages):\n",
    "    \"\"\"\n",
    "    A page is a tuple of (title, text)\n",
    "    \"\"\"\n",
    "    prs = Presentation()\n",
    "    bullet_slide_layout = prs.slide_layouts[1]\n",
    "    for page in pages:\n",
    "        \n",
    "        slide = prs.slides.add_slide(bullet_slide_layout)\n",
    "        shapes = slide.shapes\n",
    "\n",
    "        title_shape = shapes.title\n",
    "        body_shape = shapes.placeholders[1]\n",
    "\n",
    "        title_shape.text = page[0]\n",
    "\n",
    "        tf = body_shape.text_frame\n",
    "        tf.text = page[1]\n",
    "\n",
    "    prs.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_input(filename):\n",
    "    \"\"\"\n",
    "    Read the inputfile, try big5 and utf8 codecs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with codecs.open(filename, mode='r', encoding='utf8') as f:\n",
    "            text = f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with codecs.open(filename, mode='r', encoding='big5') as f:\n",
    "            text = f.read()\n",
    "    return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(input_filename, output_filename):\n",
    "    context = open_input(input_filename)\n",
    "    pages = []\n",
    "    for candidate in candidate_filter(context):\n",
    "        bucket = get_bucket(candidate)\n",
    "        page = format_bucket(bucket)\n",
    "        pages.append(page)\n",
    "    to_pptx(output_filename, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main('data/utf8.txt', 'hello.pptx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chinese_number = '廿一'\n",
    "pattern = r'((?P<hundred>.百)?)(?P<lesser_than_100>{})'.format('[一二三四五六七八九十廿卅]*')\n",
    "number = 0\n",
    "m = re.match(pattern, chinese_number)\n",
    "\n",
    "    \n",
    "if m.group('hundred'):\n",
    "    number += number_map[m.group('hundred')[0]] * 100\n",
    "lesser_than_100 = m.group('lesser_than_100')\n",
    "pattern = r'(?P<ten>.十)?(?P<one>.+)'\n",
    "m = re.match(pattern, lesser_than_100)\n",
    "if m.group('ten'):\n",
    "    number += number_map[m.group('ten')[0]] * 10\n",
    "if m.group('one'):\n",
    "    number += sum([number_map[char] for char in m.group('one')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesser_than_100='廿一'\n",
    "pattern = r'(?P<ten>.十)?(?P<one>.+)'\n",
    "m = re.match(pattern, lesser_than_100)\n",
    "if m.group('ten'):\n",
    "    number += number_map[m.group('ten')[0]] * 10\n",
    "if m.group('one'):\n",
    "    number += sum([number_map[char] for char in m.group('one')])\n",
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_number('廿一')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'太初有道、道與\\u3000神同在、道就是\\u3000神。'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repository['Jhn 1:1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
